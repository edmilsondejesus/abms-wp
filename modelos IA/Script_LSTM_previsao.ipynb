{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Configurações da Rede Neural ===\n",
      "\n",
      "Resumo do Modelo:\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_89 (LSTM)              (None, 64)                16896     \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 25)                1625      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18547 (72.45 KB)\n",
      "Trainable params: 18547 (72.45 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Detalhes das Camadas:\n",
      "\n",
      "Camada 1: lstm_89\n",
      "Tipo: LSTM\n",
      "Neurônios/Unidades: 64\n",
      "Função de Ativação: tanh\n",
      "Return Sequences: False\n",
      "Regularização: {'l1': 9.999999747378752e-06, 'l2': 9.999999747378752e-05}\n",
      "\n",
      "Camada 2: dropout_89\n",
      "Tipo: Dropout\n",
      "Dropout Rate: 0.2\n",
      "\n",
      "Camada 3: dense_118\n",
      "Tipo: Dense\n",
      "Neurônios/Unidades: 25\n",
      "Função de Ativação: relu\n",
      "\n",
      "Camada 4: dense_119\n",
      "Tipo: Dense\n",
      "Neurônios/Unidades: 1\n",
      "Função de Ativação: linear\n",
      "\n",
      "Configurações do Otimizador:\n",
      "Tipo: Adam\n",
      "Learning Rate: 0.0010000000474974513\n",
      "\n",
      "Função de Loss:\n",
      "<function fazer_previsoes_futuras.<locals>.<lambda> at 0x0000013BBA3DD260>\n",
      "\n",
      "Previsões salvas em 'previsoes_futuras_2025_2035.csv'\n",
      "\n",
      "Previsões para Janeiro/2025 a Janeiro/2035:\n",
      "          Data  Valor Previsto\n",
      "0   2025-01-01   180626.609375\n",
      "1   2025-02-01   180203.671875\n",
      "2   2025-03-01   179109.734375\n",
      "3   2025-04-01   176688.500000\n",
      "4   2025-05-01   175119.781250\n",
      "..         ...             ...\n",
      "116 2034-09-01   175959.281250\n",
      "117 2034-10-01   175959.281250\n",
      "118 2034-11-01   175959.296875\n",
      "119 2034-12-01   175959.296875\n",
      "120 2035-01-01   175959.296875\n",
      "\n",
      "[121 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def print_model_summary(model):\n",
    "    \"\"\"Função para imprimir o resumo e configurações do modelo\"\"\"\n",
    "    print(\"\\n=== Configurações da Rede Neural ===\")\n",
    "    \n",
    "    # Imprime o resumo padrão do modelo\n",
    "    print(\"\\nResumo do Modelo:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Obtém e imprime os detalhes de cada camada\n",
    "    print(\"\\nDetalhes das Camadas:\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        print(f\"\\nCamada {i+1}: {layer.name}\")\n",
    "        print(f\"Tipo: {layer.__class__.__name__}\")\n",
    "        if hasattr(layer, 'units'):\n",
    "            print(f\"Neurônios/Unidades: {layer.units}\")\n",
    "        if hasattr(layer, 'activation'):\n",
    "            print(f\"Função de Ativação: {layer.activation.__name__}\")\n",
    "        if hasattr(layer, 'return_sequences'):\n",
    "            print(f\"Return Sequences: {layer.return_sequences}\")\n",
    "        if hasattr(layer, 'rate'):\n",
    "            print(f\"Dropout Rate: {layer.rate}\")\n",
    "        if hasattr(layer, 'kernel_regularizer') and layer.kernel_regularizer:\n",
    "            print(f\"Regularização: {layer.kernel_regularizer.get_config()}\")\n",
    "    \n",
    "    # Obtém a configuração do otimizador\n",
    "    optimizer = model.optimizer\n",
    "    print(\"\\nConfigurações do Otimizador:\")\n",
    "    print(f\"Tipo: {optimizer.__class__.__name__}\")\n",
    "    print(f\"Learning Rate: {optimizer.learning_rate.numpy()}\")\n",
    "    \n",
    "    # Obtém a função de loss\n",
    "    print(\"\\nFunção de Loss:\")\n",
    "    print(model.loss)\n",
    "\n",
    "def fazer_previsoes_futuras():\n",
    "    # Carregar modelo e scaler\n",
    "    model = load_model('melhor_modelo.h5', custom_objects={'mape_loss': lambda y_true, y_pred: 0})\n",
    "    scaler = joblib.load('scaler.save')\n",
    "    \n",
    "    # Imprimir configurações do modelo\n",
    "    print_model_summary(model)\n",
    "    \n",
    "    # Carregar dados históricos para obter a última janela\n",
    "    path = 'E:\\\\Projetos\\\\ABMS-WP'\n",
    "    caminho_arquivo = os.path.join(path, 'includes\\\\Tabela_consumo_Itapua_120m.csv')\n",
    "    df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "    df['AM_REFERENCIA'] = pd.to_datetime(df['AM_REFERENCIA'], format='%Y%m')\n",
    "    df_aggregated = df.groupby('AM_REFERENCIA')['HCLQTCON'].sum().reset_index()\n",
    "    df_aggregated = df_aggregated.sort_values(by='AM_REFERENCIA')\n",
    "    \n",
    "    # Normalizar dados históricos\n",
    "    ts_scaled = scaler.transform(df_aggregated[['HCLQTCON']]).flatten()\n",
    "    \n",
    "    # Preparar a última janela de dados para previsão\n",
    "    look_back = 6\n",
    "    last_window = ts_scaled[-look_back:]\n",
    "    \n",
    "    # Gerar datas futuras (janeiro/2025 a janeiro/2035)\n",
    "    future_dates = pd.date_range(start='2025-01-01', end='2035-01-01', freq='MS')\n",
    "    \n",
    "    # Fazer previsões passo a passo\n",
    "    future_predictions = []\n",
    "    current_window = last_window.copy()\n",
    "    \n",
    "    for _ in range(len(future_dates)):\n",
    "        # Preparar entrada para o modelo\n",
    "        x = current_window.reshape(1, look_back, 1)\n",
    "        \n",
    "        # Fazer previsão\n",
    "        pred = model.predict(x, verbose=0)\n",
    "        \n",
    "        # Armazenar previsão\n",
    "        future_predictions.append(pred[0, 0])\n",
    "        \n",
    "        # Atualizar janela (descartar o mais antigo, adicionar a previsão)\n",
    "        current_window = np.append(current_window[1:], pred[0, 0])\n",
    "    \n",
    "    # Desnormalizar as previsões\n",
    "    future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Criar DataFrame com resultados\n",
    "    results_df = pd.DataFrame({\n",
    "        'Data': future_dates,\n",
    "        'Valor Previsto': future_predictions\n",
    "    })\n",
    "    \n",
    "    # Salvar em CSV\n",
    "    results_df.to_csv('previsoes_futuras_2025_2035.csv', index=False)\n",
    "    print(\"\\nPrevisões salvas em 'previsoes_futuras_2025_2035.csv'\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "resultados = fazer_previsoes_futuras()\n",
    "print(\"\\nPrevisões para Janeiro/2025 a Janeiro/2035:\")\n",
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
